"""
Action potential simulations, pacing a model cell at regular intervals.

.. seealso:: modules :mod:`protocols`, :mod:`utils.ap_stats`
"""
from __future__ import with_statement # Encapsulated try...finally
from __future__ import division # 7 / 4 = 1.75 rather than 1
import inspect
from collections import namedtuple, deque
# pysundials wrapper for python functions autogenerated from CellML
from cellmlmodels.cellmlmodel import Cellmlmodel
from cvodeint import CvodeException
import ctypes
import numpy as np
from pysundials import cvode
from numpy import r_, c_
from utils import ap_stats
from utils.ordereddict import OrderedDict
# import logging
# logging.basicConfig()

class Bond(Cellmlmodel):
    """
    CellML implementation of the Bondarenko (2004) heart cell model
    
    .. todo:: 
    
       Make this a generic class for action potential models. It started out 
       wrapping the Bondarenko model, but applies to any model for the 
       transmembrane potential.
       
       .. inheritance-diagram:: Bond Li Li_uhc Tentusscher Fitz Ff Bond_uhc Serca Hodgkin
          :parts: 1
    
    
    The :meth:`ap` method simulates an action potential using the model's 
    time-dependent stimulus current, computing action potential duration and 
    related statistics using the  
    `rootfinding
    <https://computation.llnl.gov/casc/sundials/documentation/cv_guide/node3.html#SECTION00340000000000000000>`_
    facilities of CVODE. The method :meth:`ap_plain` does the same without 
    using the rootfinding features of CVODE, though a little less accurately.
    
    .. plot::
       :width: 500

       from pylab import *
       from ap_cvode import Bond
       bond = Bond()
       t, y, stats = bond.ap()
       iv = stats["i"]
       ic = stats["caistats"]["i"]
       plot(t, y.V, 'b', label="V")
       plot(t[iv], y.V[iv], 'bo')
       xlabel("Time (ms)")
       ylabel("Voltage (mV)")
       twinx().plot(t, y.Cai, 'r', t[ic], y.Cai[ic], 'ro')
       ylabel("Cai (um)")
    
    The default initial state is not at equilibrium dynamics for calcium.
    It does not get within 75% of recovery during the first stimulus interval, 
    and so the calcium decay rate, ctd75 and ctd90 are undefined.
    
    >>> from pylab import *
    >>> from ap_cvode import Bond
    >>> bond = Bond()
    >>> t, y, stats = bond.ap()
    >>> from pprint import pformat, pprint
    >>> print pformat(stats).replace("NaN", "nan")  # nan/Nan depends on version
    {'amp': array([ 115.44...]),
     'base': array([-82.4202]),
     'caistats': {'amp': 0.525...,
      'base': 0.11500...,
      'decayrate': nan,
      'i': array([...]),
      'p_repol': array([ 0.25,  0.5 ,  0.75,  0.9 ]),
      'peak': 0.640...,
      't_repol': array([ 32.17..., 56.517..., nan, nan]),
      'ttp': 15.6...},
     'decayrate': array([ 0.09111...]),
     'i': array([...]),
     'p_repol': array([ 0.25,  0.5 ,  0.75,  0.9 ]),
     'peak': array([ 33.022...]),
     't_repol': array([  3.31010...,   5.1251...,  14.2827...,  22.789...]),
     'ttp': 1.848...}
    
    >>> bond = Bond()
    >>> t, y, stats = bond.ap_plain()
    >>> pprint(stats)
    {'amp': 115.44...,
     'base': -82.420...,
     'caistats': {'amp': 0.525...},
     'decayrate': array([ 0.0911...
     'peak': 33.021...,
     't_repol': array([  3.3101...,   5.125...,  14.282...,  22.78...]),
     'ttp': 1.844...}
    
    Doctest to alert if numerical results change.
    
    >>> [float(np.trapz(y[k], t, axis=0)) for k in "V", "Cai", "Cass"]
    [-4963.9..., 31.50..., 376.0...]
    """
    
    def ap(self, y=None, p_repol=r_[0.25, 0.5, 0.75, 0.9], ignore_flags=False):
        r"""
        Simulate action potentials as triggered by a stimulus current.
        
        :param array_like y: initial state
        :param array_like p_repol: compute action potential duration to 
           :math:`p_{repol} \times 100\%` repolarization
        :param bool ignore_flags: disable sanity checking of the shape of the 
           action potential
        
        >>> bond = Bond()
        >>> t, y, stats = bond.ap()
        >>> from pprint import pprint # platform-independent order of dict items
        >>> pprint(stats)
        {'amp': array([ 115.44...]),
         'base': array([-82.4202]),
         'caistats': {'amp': 0.525...},
         'decayrate': array([ 0.0911...
         'peak': array([ 33.02207...]),
         't_repol': array([  3.31010...,   5.1251...,  14.2827...,  22.7895...]),
         'ttp': 1.848016...}
        
        Stimulation starts at time 0.0, overriding any default in the CellML:
        
        >>> bond.pr.stim_start
        array([ 0.])
        
        Parameters governing the stimulus setup:
        
        >>> [(s, bond.pr[s]) for s in bond.pr.dtype.names
        ...     if s.startswith("stim_")]
        [('stim_start', array([ 0.])), 
         ('stim_end', array([ 100000.])),
         ('stim_period', array([ 71.43])),
         ('stim_duration', array([ 0.5])),
         ('stim_amplitude', array([-80.]))]
        
        Calling :meth:`ap` again resumes from the previous state, resetting 
        time to 0:
        
        >>> t1, Y1, stats1 = bond.ap()
        
        Fixed: Setting the state vector before calling :meth:`ap` now works 
        correctly.
        
        >>> for V0 in bond.y0r.V + [-5, 0, 5]:
        ...     bond.y[:] = bond.model.y0
        ...     bond.yr.V = V0
        ...     t, y, stats = bond.ap()
        ...     assert y.V[0] == V0

        Check that ``bond.y0r`` is not overwritten when the model is integrated:
        
        >>> bond.y[:] = bond.model.y0
        >>> t, y, stats = bond.ap()
        >>> print y.V[-1], bond.y0r.V
        [-84.000...] [-82.4202]

        Module-level variables are shared between instances!
        
        >>> b0 = Bond(); b1 = Bond()
        >>> original_y00 = b0.model.y0[0]
        >>> b0.model.y0 is b1.model.y0
        True
        >>> b0.model.y0[0] = 12345
        >>> b1.model.y0[0]
        12345.0
        >>> b1.y0r.V = 54321
        >>> b0.y0r.V
        array([ 54321.])
        
        Reset the defaults so we don't mess up other doctests:
        
        >>> b0.y0r.V = original_y00
        >>> assert b0.y0r.V == b1.model.y0[0] == original_y00

        Effect of tolerances:
        
        .. plot::
            :width: 300
        
            from pylab import *
            from ap_cvode import Bond
            for tol in 1e-6, 1e-2:
                t, y, stats = Bond(reltol=tol).ap()
                plot(t, y.V, '.-', label="reltol={:.0e}".format(tol))
                i = stats["i"]
                plot(t[i], y.V[i], 'ro')
            xlim(1.6, 2.2)
            ylim(32, 33.1)
            legend()
        
        If the action potential does not have the expected shape, for example 
        due to an insufficient stimulus, an exception explains that the 
        integrator returned an unexpected flag.
        
        >>> with bond.autorestore(stim_amplitude=0):
        ...     t, y, stats = bond.ap()
        Traceback (most recent call last):
        CvodeException: CVode returned CV_TSTOP_RETURN
        
        Note that we can suppress the exception and still have reasonable output.
        
        >>> with bond.autorestore(stim_amplitude=0):
        ...     t, y, stats = bond.ap(ignore_flags=True)
        """
        
        if y is None:
            y = self.y
        self._ReInit_if_required(t=0, y=y)
        
        result = [] # list to keep results from integration subintervals
        
        # integrate over stimulus
        result.append(self.integrate(t=[0, self.pr.stim_duration], y=y, nrtfn=0,  
            assert_flag=cvode.CV_TSTOP_RETURN, ignore_flags=ignore_flags))
        
        # integrate from stimulus to peak
        j_peak = 0 # index to "result" item ending with peak
        # make sure we don't stop at a minor peak at end of stimulus
        # repeat until we are at an extremum with V > 0
        while True:
            j_peak += 1
            result.append(self.integrate(t=self.pr.stim_period, 
                nrtfn=1, g_rtfn=self.vdot(), assert_flag=cvode.CV_ROOT_RETURN, 
                ignore_flags=ignore_flags))
            tj, yj, flagj = result[-1]
            if (flagj == cvode.CV_TSTOP_RETURN) or (yj.V[-1] > 0):
                break
        
        # compute repolarization thresholds
        Vmin = result[0][1][0].V # 1st integration, 2nd return var, 1st step
        # was: Vmax = result[-1][1][-1].V
        Vmax = yj.V[-1] # last integration, 2nd return var, last step
        V_repol = Vmax - p_repol * (Vmax - Vmin)        
        
        # integrate to each repolarization threshold in turn
        g_rtfn = self.repol()
        result += [self.integrate(t=self.pr.stim_period,
            nrtfn=1, g_rtfn=g_rtfn, g_data=ctypes.byref(ctypes.c_float(x)),
            assert_flag=(cvode.CV_ROOT_RETURN, cvode.CV_TSTOP_RETURN), 
            ignore_flags=ignore_flags)
            for x in V_repol]
        
        # If time has run out, flag is None but flagj is CV_TSTOP_RETURN
        if result[-1][-1] == cvode.CV_ROOT_RETURN:
            # integrate from repolarization to next stimulus:
            result.append(self.integrate(t=self.pr.stim_period, nrtfn=0, 
                assert_flag=cvode.CV_TSTOP_RETURN, ignore_flags=ignore_flags))        
        
        # drop intervals where flag is None; those were past t_stop
        result = [res for res in result if res[-1] is not None]
        t, Y, flag = zip(*result) # (t, Y, flag), where each is a tuple
        
        # The items of the tuples refer to these intervals, assuming the
        # default p_repol specifying four thresholds:
        # 0) stimulus
        # ...+ possibly more here, waiting for some extremum V >= 0...
        # 1) stimulus to peak,
        # 2) peak to first repolarization threshold
        # 3) first to second repolarization threshold
        # 4) second to third repolarization threshold
        # 5) third to fourth repolarization threshold
        # 6) fourth repolarization threshold to just before next stimulus
        
        stats = {"base": Y[0][0].V, "ttp": t[j_peak][-1], 
            "peak": Y[j_peak][-1].V, "p_repol": p_repol}
        # summarize "result" items for repolarization (items _after_ j_peak)
        stats["t_repol"] = np.array([ti[-1]
            for ti, Yi, flagi in result[j_peak + 1:]
            if flagi == cvode.CV_ROOT_RETURN])
        # keep indices for j_peak and later items
        stats["i"] = np.cumsum([len(ti) for ti in t])[j_peak:-1] - 1        
        # concatenation converts recarray to ndarray, so need to convert back
        Y = np.concatenate(Y).view(np.recarray)
        t = np.concatenate(t)
        # just use (arg)max if rootfinding didn't work:
        if len(stats["i"]) == 0:
            stats["i"] = [np.argmax(Y.V)] # ensures that t[stats["i"]] is array
            stats["peak"] = Y.V[stats["i"]]
            stats["ttp"] = t[stats["i"]]
            stats["t_repol"] = []
            stats["p_repol"] = []
        try:
            stats["decayrate"] = ap_stats.apd_decayrate(stats)
        except ValueError:
            stats["decayrate"] = np.nan
        stats["amp"] = stats["peak"] - stats["base"]
        
        assert t[stats["i"]][0] == stats["ttp"]
        ti = t[stats["i"]][1:]
        trepol = stats["t_repol"]
        maxlen = min(len(ti),len(trepol))
        assert (ti[:maxlen]==trepol[:maxlen]).all()
        try:
            sc = stats["caistats"] = ap_stats.apd(t, Y.Cai)
            # don't bother to report Ca decay rate for very small oscillations 
            if (sc["amp"] / sc["peak"]) < 1e-3:
                sc["decayrate"] = np.nan
        except AttributeError: # model may not have a state variable called Cai
            pass
        return t, Y, stats

    def ap_plain(self, y=None, pr=None, p_repol=r_[0.25, 0.5, 0.75, 0.9], ignore_flags=False):
        """
        Simulate action potential triggered by stimulus current. No rootfinding.
        
        Arguments are as for :meth:`ap`.
        
        >>> bond = Bond()
        >>> t, y, stats = bond.ap_plain()
        >>> from pprint import pprint # platform-independent order of dict items
        >>> pprint(stats)
        {'amp': 115.44...,
         'base': -82.4201999...,
         'caistats': {'amp': 0.525...},
         'decayrate': array([ 0.0911...
         'peak': 33.021572...,
         't_repol': array([  3.31012...,   5.125...,  14.282...,  22.78...]),
         'ttp': 1.844189...}
        
        The arguments *y* and *pr* are largely obsolete; use 
        :meth:`~cvodeint.namedcvodeint.Namedcvodeint.autorestore` 
        instead to temporarily modify initial state or parameters.
        
        >>> with bond.autorestore(V=-60, stim_period=50):
        ...     t, y, stats = bond.ap_plain()
        >>> t[-1]
        50.0
        >>> pprint(stats)
        {'amp': 87.75...,
         'base': -60.0,
         'caistats': {'amp': 0.208...},
         'decayrate': array([ 0.195...
         'peak': 27.75...,
         't_repol': array([  2.562...,   3.667...,   7.152...,  11.882...]),
         'ttp': 1.342...}
        """
        
        if y is None:
            y = self.y
        if pr is not None:
            self.pr[:] = pr
        self._ReInit_if_required(t=0, y=y)
        
        result = [] # list to keep results from integration subintervals

        # integrate over stimulus
        # logging.debug("integrate over stimulus")
        result.append(self.integrate(t=[0, self.pr.stim_duration], y=y, nrtfn=0,  
            assert_flag=cvode.CV_TSTOP_RETURN, ignore_flags=ignore_flags))
        
        # integrate from the end of this stimulus to the start of the next one:
        # logging.debug("integrate from end of stimulus to start of next")
        # RHS discontinuity here, so force the solver to re-initialize: len(t)>1
        result.append(self.integrate(t=[self.pr.stim_duration, self.pr.stim_period], nrtfn=0, 
            assert_flag=cvode.CV_TSTOP_RETURN, ignore_flags=ignore_flags))
        
        # logging.debug("integration finished")
        t, Y, flag = zip(*result) # (t, Y, flag), where each is a tuple
        
        # The items of the tuples refer to these intervals
        # 0) stimulus
        # 1) stimulus to just before next stimulus
        
        # concatenation converts recarray to ndarray, so need to convert back
        Y = np.concatenate(Y).view(np.recarray)
        t = np.concatenate(t)
        # logging.debug("computing action potential duration")
        stats = ap_stats.apd(t, Y.V, p_repol=p_repol)
        assert t[stats["i"]][0] == stats["ttp"]
        try:
            sc = stats["caistats"] = ap_stats.apd(t, Y.Cai)
            # don't bother to report Ca decay rate for very small oscillations 
            if (sc["amp"] / sc["peak"]) < 1e-3:
                sc["decayrate"] = np.nan
        except AttributeError: # model may not have a state variable called Cai
            pass
        return t, Y, stats
    
    def aps(self, n=5, y=None, pr=None, *args, **kwargs):
        """
        Consecutive stimulus-induced action potentials using :meth:`ap_plain`.
        
        :param n: number of action potentials to run
        :param array_like y: initial state
        :param array_like pr: parameter set, or a sequence of one parameter set 
          for each action potential, in which case ``n = len(pr)`` is used.
        :rtype: list of one (time, states, stats) tuple per action potential
        
        Further arguments are passed to :meth:`ap_plain`.
        
        >>> bond = Bond()
        >>> aps = list(bond.aps(n=2))
        
        You can iterate over the list of tuples like so:
        
        >>> from pprint import pprint
        >>> for t, y, stats in aps:
        ...     print t[-1], y[-1].V
        ...     pprint(stats)
        71.43 [-84.000...]
        {'amp': 115.44...,
         'caistats': {'amp': 0.525...},
         'decayrate': array([ 0.0911...}
        142.86 [-84.072...]
        {'amp': 110.86...,
         'caistats': {'amp': 0.208...},
         'decayrate': array([ 0.0932...}
        
        Separate lists for time, states, stats:
        
        >>> t, y, stats = zip(*aps)
        
        Time is reckoned consecutively, not restarting for each action potential.
        
        >>> t[0][-1] == t[1][0]
        True
        
        Parameters can vary between intervals by specifying *pr* as a list.
        
        >>> p = np.tile(bond.pr, 3)
        >>> p["stim_period"] = 20, 30, 40
        >>> with bond.autorestore():
        ...     [ti[-1] for ti, yi, statsi in bond.aps(pr=p)]
        [20.0, 50.0, 90.0]
        
        In case of a :exc:`~cvodeint.core.CvodeException`, the exception 
        instance has a *result* attribute with the results thus far: 
        A list of *(t, y, stats)*, where *stats* is *None* for the failed action 
        potential.
                
        (Doctests to guard against accidental changes.)
        
        >>> ix = np.r_[0:2, -2:0]
        >>> t[1][ix]
        array([  71.43      ,   71.43012...,  142.85999...,  142.86      ])
        >>> y[1].V[ix]
        array([[-84.000...], [-83.99...], [-84.07...], [-84.07...]])
        """
        t0 = 0.0
        y0 = y
        if pr is None:
            pr = np.tile(self.pr, n)
        else:
            n = len(pr)
        
        for p in pr:
            t, y, stats = self.ap_plain(y0, p, *args, **kwargs)
            t = t + t0
            yield t, y, stats
            t0, y0 = t[-1], y[-1]
    
    def period(self, _burnin=0, _pmax=10, _tol=0.01, _return_aps=False, 
        *args, **kwargs):
        r"""
        Estimate periodicity of action potential and calcium transient.
        
        The algorithm runs *_burnin* stimuli for approximate convergence, 
        then up to *_pmax* stimuli until the first action potential peak > 0,
        then up to *_pmax* stimuli until the calcium transient peak is within 
        _tol :math:`\times` 100% 
        of the previous Cai peak.
        (This will fail if the dynamics has not adequately burned in: 
        subsequent Cai peaks will be too different, and a period of infinity 
        will be returned.)
        Optional parameters ``*args``, ``**kwargs`` are passed to 
        :meth:`~cvodeint.namedcvodeint.Namedcvodeint.autorestore`.
        
        >>> bond = Bond()
        >>> bond.period() # not converged yet
        inf
        
        The following doctests are slow, so I normally skip them.
        
        >>> bond.period(_burnin=20) # doctest: +SKIP
        1.0
        >>> bond.period(_burnin=25, Ko=0.5*bond.pr.Ko, g_Na=1.5*bond.pr.g_Na)
        ... # doctest: +SKIP
        4.0
        """
        with self.autorestore(*args, **kwargs):
            # burn in
            for t, y, V_stats in self.aps(n=_burnin):
                pass
            # find first peak > 0 (if any) in "n" intervals
            peak = False
            try:
                for t, y, V_stats in self.aps(n=_pmax):
                    Cai_peak = ap_stats.apd(t, y.Cai)["peak"]
                    if V_stats["peak"] > 0:
                        if _return_aps:
                            aps = [(t, y, V_stats)]
                        peak = True
                        break
                if not peak:
                    return np.inf
                # run for "n" more intervals and estimate periodicity of Cai
                for period, (t, y, V_stats) in enumerate(self.aps(n=_pmax)):
                    if _return_aps:
                        aps.append((t, y, V_stats))
                    if abs(1 - ap_stats.apd(t, y.Cai)["peak"]/Cai_peak) < _tol:
                        result = np.float(period + 1)
                        return (result, aps) if _return_aps else result
                return np.inf
            except CvodeException:
                return np.nan
    
    def restitution_portrait(self, BCL0=1000, delta=50, Delta=100, 
        tburnin=60000, nbetween=10, p_repol=0.70, *args, **kwargs):
        r"""
        Restitution portrait sensu :doi:`Kalb et al. 2004 <10.1046/j.1540-8167.2004.03550.x>`.
        
        All times are in milliseconds.
        
        :param BLC0: Initial basic cycle length
        :param delta: Change in cycle length for single-beat perturbations
        :param Delta: Change in cycle length between runs towards steady state
        :param tburnin: Burn-in period towards steady state
        :param nbetween: Number of stimuli separating the steps of the protocol
        :param p_repol: Use :math:`APD_{p\times100\%}` for action potential 
            duration
        
        Further arguments are passed to :meth:`ap_plain`.
        
        The protocol prescribes six steps that are repeated until 2:1 alternans 
        occurs. Default parameters take about five minutes.
        
        The return value is a list of lists of named tuples with fields: 
        
        * *step* : Roman numeral
        * *name* : name of step as defined by :doi:`Kalb et al. 2004 <10.1046/j.1540-8167.2004.03550.x>`
        * *bcl* : basic cycle length
        * *description* : description of step
        * *R* : recovery curve; record array with names *di*, *apd* for 
          diastolic interval and action potential duration
        
        Model state and parameters are restored to their initial values 
        after running the protocol.
        
        Usage examples; not yet quality-controlled doctests.
        
        >>> from ap_cvode import Li
        >>> li = Li()
        >>> rp = li.restitution_portrait(BCL0=150, tburnin=500, nbetween=5)
        >>> rp
        <generator object restitution_portrait at 0x...>
        >>> L = list(rp)
        >>> last_step = L[-1][-1]
        >>> last_step
        Step(step='VI', name='RCB-S', bcl=[50, 50, 50, 50, 50], 
        description='Recovery toward steady state', 
        R=rec.array([(39.84..., 10.58...), (39.41..., 10.53...), 
                     (39.46..., 10.52...), (39.47..., 10.54...)], 
        dtype=[('di', '<f8'), ('apd', '<f8')]))
        >>> [[len(i.R) for i in j] for j in L]
        [[3, 5, 1, 5, 1, 4], [10, 5, 1, 5, 1, 4]]
        """
        Step = namedtuple("Step", "step name bcl description R")
        while True: # until a 2:1 response occurs
            # Perturbed downsweep pacing protocol, Kalb et al. p. 699
            nburnin = tburnin // BCL0
            pacingprotocol = [Step(*i, R=None) for i in [ 
                # Step  Name     Basic cycle length    Description
                ["I",   "RCB-D", [BCL0] * nburnin,  "Burn-in to steady state"], 
                ["II",  "R*",    [BCL0] * nbetween, "Measure at steady state"], 
                ["III", "RL",    [BCL0 + delta],    "Long coupling interval"], 
                ["IV",  "RCB-S", [BCL0] * nbetween, "Recovery toward steady state"],
                ["V",   "RS",    [BCL0 - delta],    "Short coupling interval"], 
                ["VI",  "RCB-S", [BCL0] * nbetween, "Recovery toward steady state"]
            ]]
            bcl = np.concatenate([step.bcl for step in pacingprotocol])
            pr = np.tile(self.pr, len(bcl))
            pr.stim_period = bcl
            with self.autorestore():
                aps = self.aps(pr=pr, p_repol=p_repol, *args, **kwargs)
                apd = [float(stats["t_repol"]) for t, y, stats in aps]
            di = pr.stim_period - apd
            R = np.rec.fromarrays([di[:-1], apd[1:]], names="di, apd")
            # split back into steps
            splits = np.cumsum([len(step.bcl) for step in pacingprotocol])            
            RL = np.array_split(R, splits[:-1])
            yld = [step._replace(R=rl) for step, rl in zip(pacingprotocol, RL)]
#             
#             # Fit dynamic restitution curve
#             # APD = a - b exp(-DI/tau) for all R*
#             # ln(APD-a) = ln b - (1/tau) DI
#             from rnumpy import r
            Rs, = [step.R for step in yld if step.name == "R*"]
            a, b = np.linalg.lstsq(np.c_[np.ones_like(Rs.di), Rs.di], Rs.apd)[0]
            # start = dict(a=mean(Rstar.apd), b=0, tau=1)
            # r.nls("apd ~ a - b * exp(- di / tau)", rec2dict(Rstar), start=start)

            yield yld
            BCL0 = BCL0 - Delta
            # Check for "2:1 response", whatever that means
            if BCL0 <= self.pr.stim_duration:
                break # while

    def __init__(self, exposure_workspace="11df840d0150d34c9716cd4cbdd164c8/"
            "bondarenko_szigeti_bett_kim_rasmusson_2004_apical", **kwargs):
        """
        Constructor for the Bondarenko model object.
        
        *exposure_workspace* is a reference to the 
        `CellML model repository <http://models.cellml.org/cellml>`_,
        see :class:`~cellmlmodels.cellmlmodel.Cellmlmodel`.
        Other keyword arguments are passed through to :meth:`Cellmlmodel`.
        
        This constructor sets :attr:`pr.stim_start` = 0.0, overriding the default.
        
        >>> bond = Bond()
        """
        super(Bond, self).__init__(exposure_workspace, **kwargs)
        self.pr.stim_start = 0.0
        # Mapping None to an empty dict, and letting the scenario name default 
        # to None, makes self.scenario() equivalent to self.autorestore().
        self.scenarios = OrderedDict({None: {}})
        ew_apex = inspect.getargspec(Bond.__init__).defaults[0]
        ew_septum = ew_apex.replace("apical", "septal")
        modelnw = [("apex", ew_apex), ("septum", ew_septum)]
        for n, w in modelnw:
            self.scenarios[n] = dict(workspace=w, 
                y=self.y0r.copy(), p=self.pr.copy())
            m = Cellmlmodel(w, **kwargs)
            m.pr.stim_start = 0.0
            for k in set(m.dtype.p.names) & set(self.dtype.p.names):
                self.scenarios[n]["p"][k] = m.pr[k]
            for k in set(m.dtype.y.names) & set(self.dtype.y.names):
                self.scenarios[n]["y"][k] = m.y0r[k]

    def vdot(self):
        """
        Return voltage rate-of-change as a function of (t, y, gout, g_data).
        
        For use with CVode's `rootfinding
        <https://computation.llnl.gov/casc/sundials/documentation/cv_guide/node3.html#SECTION00340000000000000000>`_
        functions.
        
        >>> bond = Bond()
        >>> gout = cvode.NVector([0.0])
        >>> f = bond.vdot()
        >>> f(0, bond.model.y0, gout, None)   # returns 0, as required by CVODE
        0
        >>> gout    # the actual result is written to the output parameter gout
        [80.000016441101...]
        """
        def result(t, y, gout, g_data):
            """
            Voltage rate-of-change.
            
            Use with pysundials.cvode.CVodeRootInit to find voltage peak.
            """
            self.model.ode(t, y, self.model.ydot, None)
            gout[0] = self.model.ydot[0]
            return 0
        return result

    def repol(self):
        """
        Difference between current V and repolarization threshold.
        
        .. seealso:: :func:`pysundials.cvode.CVodeRootInit`
        
        *g_data* is a void pointer in C but an integer in Python, so must be 
        typecast before use.
        
        >>> bond = Bond()
        >>> gout = cvode.NVector([0.0])
        >>> g_data = ctypes.c_float(0.0)
        >>> bond.repol()(0, bond.model.y0, gout, ctypes.byref(g_data)), gout
        (0, [-82.420...])
        >>> g_data.value = -75
        >>> bond.repol()(0, bond.model.y0, gout, ctypes.byref(g_data)), gout
        (0, [-7.420199...])
        """
        def result(t, y, gout, g_data):
            gout[0] = self.yr.V - ctypes.cast(g_data, 
                ctypes.POINTER(ctypes.c_float)).contents.value
            return 0
        return result
    
    def converged(self, x0, x1, reltol={}, abstol={}):
        """
        Convergence checking of x0[k] vs x1[k] for k in reltol and abstol.
        
        >>> bond = Bond()
        >>> with bond.autorestore():
        ...     x0, x1 = [np.trapz(y.view(float), t, axis=0).view(y.dtype) 
        ...         for t, y, stats in bond.aps(n=2)]
        >>> max([abs(j/i-1) for i, j in zip(x0.item(), x1.item())])
        2.05...
        >>> bond.converged(x0, x1, reltol=2.1)
        True
        >>> bond.converged(x0, x1, reltol=2)
        False
        
        >>> bond.converged(x0, x1)
        Traceback (most recent call last):
        AssertionError: Must specify relative or absolute tolerance
        """    
        # Note that the "reltol" we use to check convergence of action 
        # potentials is something else than the reltol used by the CVODE 
        # integrator.
        if np.isscalar(reltol):
            reltol = dict((k, reltol) for k in self.dtype.y.names)
        assert reltol or abstol, "Must specify relative or absolute tolerance"
        absconv = all([abs(x1[k] - x0[k]) < tol for k, tol in abstol.items()])
        relconv = all([abs((x1[k] - x0[k]) / x0[k]) < tol 
            for k, tol in reltol.items()])
        return relconv and absconv
    
    def par2steady(self, p=None, y0=None, winwidth=10, max_nap=1000, reltol=0.001):
        """
        Run heart cell to approximate steady state.
        
        Return value is ((period, number of intervals to convergence), steady) 
        where steady is a list of *(t, y, stats, int_)* for the last *period* 
        intervals. *int_* contains the integral of each state variable's 
        trajectory.
        If state variables include *Cai*, the cycle is aligned so that the 
        highest Cai peak occurs in *steady[0]*.
        
        If dynamics does not converge within *max_nap* intervals, *period* is zero.
        
        To speed up the doctest, we use a precomputed approximate steady state.
        
        >>> bond = Bond()
        >>> y0 = [-83.61, 0.30, 0.32, 703.76, 1167.91, 1.52e-02, 25.07, 134.76, 
        ...     1.16e-02, 1.64e-06, 0.79, 6.15e-10, 3.77e-04, 1.45e-04, 
        ...     9.67e-05, 6.85e-09, 1.02e-03, 0.14, 15493.40, 3.26e-07, 
        ...     1.49e-04, 1.27e-02, 7.86e-03, 1.27e-04, 1.91e-04, 1.56e-02, 
        ...     0.53, 141974.13, 2.36e-03, 1.00, 0.17, 0.69, 1.38e-02, 0.17, 
        ...     0.89, 0.90, 1.00, 4.79e-03, 9.07e-04, 1.91e-03, 8.43e-04]
        >>> (period, intervals), steady = bond.par2steady(y0=y0)
        >>> (t, y, stats, int_), = steady       # unpacking a 1-tuple
        >>> period, intervals, stats
        (1, 6, {'caistats': {'base': 0.298..., 'peak': 0.408...
        't_repol': array([ 31.0...,  40.2...}, 'base': -83.60..., 
        'peak': 25.35..., 't_repol': array([  3.7...,   5.7...})
        """
        with self.autorestore(_p=p, _y=y0):
            d = deque(maxlen=winwidth)
            for i, (ti, yi, statsi) in enumerate(self.aps(n=max_nap)):
                # Converged if integral of specified state variables are 
                # within tolerance of values stored in deque, i.e. at t-1, t-2, ...
                # Trapezoidal integration of trajectories
                inti = np.trapz(yi.view(float), ti, axis=0).view(yi.dtype)
                for j, (tj, yj, statsj, intj) in enumerate(reversed(d)):
                    if (self.converged(inti, intj, reltol) and 
                        self.converged(yi[0], yj[0], reltol)):
                        period = j + 1
                        steady = deque(d, maxlen=period)
                        if "Cai" in self.dtype.y.names:
                            # Ensure cycle starts with a high Cai peak
                            n = np.argmax([max(y.Cai) 
                                for t, y, stats, int_ in steady])
                            if n: # Highest Cai peak is not yet in position 0
                                # Append the next interval, already computed
                                steady.append((ti, yi, statsi, inti))
                                # Compute the remaining n-1, if any
                                for tk, yk, statsk in self.aps(n=n-1, y=yi[-1]):
                                    intk = np.trapz(yk.view(float), 
                                        tk, axis=0).view(yk.dtype)
                                    steady.append((tk + ti[-1], yk, statsk, intk))
                        t0 = steady[0][0][0]
                        result = [(tk - t0, yk, statsk, intk) 
                            for tk, yk, statsk, intk in steady]
                        return (period, i), result
                # Don't append until after we've compared against previous items
                d.append((ti, yi, statsi, inti))
            t0 = d[0][0][0]
            result = [(tk - t0, yk, statsk, intk) for tk, yk, statsk, intk in d]
            return (0, i), result # If we get here, convergence failed
    
    def dyss(self, y0=None, return_all=False):
        """
        Sum of squared changes in state variables during an action potential.
        
        Minimize this to find a fixpoint.
        """
        if y0 is None:
            y0 = self.y
        y0 = np.copy(y0)
        t, y, stats = self.ap_plain(y=y0, ignore_flags=True)
        y1 = y[-1].view(float)
        dy = y1 - y0
        if return_all:
            return np.dot(dy, dy), t, y, stats
        else:
            return np.dot(dy, dy)
    
    def fixpoint(self, maxiter=100, maxperiod=8):
        """
        Find stable dynamics of action potential, solving difference equation
        
        Experimental parameters: *stim_duration*, *stim_period*, *stim_amplitude*
        
        Brute force: Run action potentials to convergence.
        Using nonlinear zero-finding on difference in state at local time 0, 
        just before stimulus.
        Minimize norm of difference in state.
        """
        def f(y0):
            t, y, stats = self.ap(y=y0)
            return np.dot(y[-1] - y0)
    
    def scenario(self, name=None, **kwargs):
        """
        Context manager to set parameters and initial state to a named scenario.
        
        This is just a wrapper for 
        :meth:`~cvodeint.namedcvodeint.Namedcvodeint.autorestore`, 
        and defaults to a plain :meth:`autorestore` if *name*=None. 
        A Bond object has scenarios representing "apex" and "septum" cells, 
        with apex as the default.
        Subclasses may define additional scenarios. Note that scenarios will 
        need adaptation to work with subclasses that have different parameter 
        names.
        
        ``**kwargs`` are passed to 
        :meth:`~cvodeint.namedcvodeint.Namedcvodeint.autorestore`.
        
        Typical usage.       
        
        >>> bond = Bond()
        >>> with bond.scenario("septum"):
        ...     t0, y0, stats0 = bond.ap()
        
        The two scenarios are available as separate models at cellml.org.
        Verify that switching scenarios is equivalent to using the other version.
        
        >>> import inspect
        >>> exposure_workspace = inspect.getargspec(Bond.__init__).defaults[0]
        >>> septum = Bond(exposure_workspace.replace("apical", "septal"))
        >>> with septum.autorestore():
        ...     t1, y1, stats1 = septum.ap()
        
        Compare string representations to allow for machine imprecision.
        
        >>> str(ap_stats_array(stats0)) == str(ap_stats_array(stats1))
        True
        
        >>> with septum.scenario("apex"):
        ...     t2, y2, stats2 = septum.ap()
        >>> with bond.autorestore():
        ...     t3, y3, stats3 = bond.ap()
        >>> str(ap_stats_array(stats2)) == str(ap_stats_array(stats3))
        True
        """
        return self.autorestore(_y=self.scenarios[name].get("y"), 
                                _p=self.scenarios[name].get("p"), **kwargs)
    
    def apex_to_septum(self):
        """
        Hacked .autorestore() to convert apex to septum-like cell.
        
        Parameters that differ between apex and septum scenarios are 
        adjusted as follows. If the parameter is zero, replace with the septum 
        value. Otherwise, scale by the ratio of the septum to the apex value.
        
        This is intended for subclasses of :class:`Bond` that may have 
        different names of parameters, so that the Bond septum scenario cannot 
        be used directly.
        
        Note that this may not be helpful in practice. Septumizing the "ff" or 
        "ko" scenario of class :class:`Ff` gives weird alternans that may not 
        be realistic.
        
        Here is testing that it works for the Bondarenko model.
        
        >>> bond = Bond()
        >>> with bond.scenario("septum"):
        ...     t0, y0, stats0 = bond.ap()
        >>> with bond.apex_to_septum():
        ...     t1, y1, stats1 = bond.ap()
        >>> str(ap_stats_array(stats0)) == str(ap_stats_array(stats1))
        True
        """
        pa, ps = [self.scenarios[i]["p"] for i in "apex", "septum"]
        modified = [k for k in pa.dtype.names if pa[k] != ps[k]]
        kwargs = {}
        for k in modified:
            if self.pr[k] == 0:
                kwargs[k] = ps[k]
            else:
                kwargs[k] = self.pr[k] * ps[k] / pa[k]
        return self.autorestore(**kwargs)

class Li(Bond):
    """
    CellML implementation of the LNCS modified Bondarenko model by Li et al.
    
    .. seealso:: :doi:`10.1152/ajpheart.00219.2010`
    """
    
    def __init__(self, exposure_workspace="/BL6WT_260710", **kwargs):
        """
        Return a Li-Niederer-Casadei-Smith (LNCS) model object.
        
        "exposure_workspace" will eventually refer to the cellml.org repository.
        Currently, I work with code generated from the CellML file using 
        OpenCell 0.8.
        Other keyword arguments are passed through to 
        :mod:`cellmlmodels.cellmlmodel.Cellmlmodel`.
        
        >>> li = Li()
        >>> t, y, stats = li.ap()
        >>> from pprint import pprint
        >>> pprint(stats)
        {'amp': array([ 115.42819999]),
         'base': array([-78.9452...
         'peak': array([ 36.4829...,
         't_repol': array([  4.285...,   5.699...,  10.216...,  17.281...]),
         'ttp': 3.1455...}
        
        This constructor sets *stim_offset* = 0.0, overriding the default. 
        This is because the stepwise integration assumes that the stimulus is 
        at the start of the action potential.
        """
        super(Li, self).__init__(exposure_workspace, **kwargs)
        # Assume AP starts with stimulus
        self.pr.stim_offset = 0.0
        # Disable caffeine injection unless specifically requested
        if "prepulses_number" in self.pr.dtype.names:
            self.pr.prepulses_number = np.inf

class Ff(Li):
    """
    LNCS model fitted to flox/flox control mice from Ulleval calcium experiments.
    
    This model can represent several models in the same parameter space
    with the following scenarios:
    
    * ff (flox-flox), 051110_caffeine.cellml :
      fitted to control data from Ulleval calcium experiments.
    * ko (knockout), 051110KO_caffeine.cellml :
      fitted to SERCA knockout data from Ulleval.
    * bl6 (black 6), BL6WT_260710 :
      fitted to wild type data in Oxford, see 
      :doi:`Li et al. 2010 <10.1152/ajpheart.00219.2010>`.
    
    This example verifies that a FF model with BL6 parameters behaves like the 
    original BL6 to within roundoff error. 
    
    .. plot::
       :width: 300
    
       from ap_cvode import Li, Ff
       li, ff = Li(), Ff()
       t0, y0, stats0 = li.ap()
       with ff.scenario("bl6"):
           t1, y1, stats1 = ff.ap()
       plt.semilogy(t0, y0.view(float), 'r-')
       plt.semilogy(t1, y1.view(float), 'b.')
    
    Show that the integral of squared deviation between (t0, y0[k]) and 
    (t1, y1[k]) is small.
    
    >>> from scipy.interpolate import interp1d
    >>> from scipy.integrate import trapz
    >>> from ap_cvode import Li, Ff
    >>> li, ff = Li(), Ff()
    >>> t0, y0, stats0 = li.ap()
    >>> with ff.scenario("bl6"):
    ...     t1, y1, stats1 = ff.ap()
    >>> for k in ff.dtype.y.names:
    ...     f0 = interp1d(t0, y0[k].squeeze())
    ...     f1 = interp1d(t1, y1[k].squeeze())
    ...     def dev2(t):
    ...         return (f0(t) - f1(t)) ** 2
    ...     # Relative error
    ...     rer = trapz(dev2(t0), t0) / trapz(y0[k].squeeze(), t0)
    ...     try:
    ...         np.testing.assert_almost_equal(rer, 0, decimal=5, err_msg=k)
    ...     except AssertionError, exc:
    ...         print exc
   
    Verify that class Ff can imitate a SERCA knockout.
    
    >>> ko = Li("/_051110KO_caffeine")
    >>> t0, y0, stats0 = ko.ap()
    >>> with ff.scenario("ko"):
    ...     t1, y1, stats1 = ff.ap()
    >>> for k in ff.dtype.y.names:
    ...     f0 = interp1d(t0, y0[k].squeeze())
    ...     f1 = interp1d(t1, y1[k].squeeze())
    ...     def dev2(t):
    ...         return (f0(t) - f1(t)) ** 2
    ...     # Relative error
    ...     rer = trapz(dev2(t0), t0) / trapz(y0[k].squeeze(), t0)
    ...     try:
    ...         np.testing.assert_almost_equal(rer, 0, decimal=5, err_msg=k)
    ...     except AssertionError, exc:
    ...         print exc
    
    Verify that the "ff" scenario is the same as the default.
    
    >>> t0, y0, stats0 = ff.ap()
    >>> with ff.scenario("ff"):
    ...     t1, y1, stats1 = ff.ap()
    >>> all(y0==y1)
    True
    """

    def __init__(self, exposure_workspace="/_051110_caffeine_jov", **kwargs):
        """
        Return a flox/flox LNCS model with black 6 and SERCA knockout scenarios.
        """
        super(Ff, self).__init__(exposure_workspace, **kwargs)
        # Augment the Bond scenarios dict with 
        # initial state and parameters for three model scenarios.
        modelnw = [("ff", "/_051110_caffeine_jov"), 
                   ("ko", "/_051110KO_caffeine"), 
                   ("bl6", "/BL6WT_260710")]
        for n, w in modelnw:
            self.scenarios[n] = dict(workspace=w, 
                                     y=self.y0r.copy(), p=self.pr.copy())
            m = Cellmlmodel(w)
            m.pr.stim_start = 0.0
            for k in set(m.dtype.p.names) & set(self.dtype.p.names):
                self.scenarios[n]["p"][k] = m.pr[k]
            for k in set(m.dtype.y.names) & set(self.dtype.y.names):
                self.scenarios[n]["y"][k] = m.y0r[k]
        manualvars = dict(ko=dict(y_gate_tau_offset=19, y_gate_tau_denom=2.7), 
            bl6=dict(delta_VupCaMK_max=2.9982, Km_CaMK=1.2444, n_CaMK=2.583, 
            y_gate_tau_const1=315, y_gate_tau_const2=8, y_gate_tau_offset=30, 
            y_gate_tau_denom=4, ass_offset=6.19, ass_denom=9.6))
        for n, d in manualvars.items():
            for k, v in d.items():
                self.scenarios[n]["p"][k] = v

class Tentusscher(Bond):
    """
    CellML implementation of the Tentusscher et al. (2004) heart M-cell model.
    
    Wrapper for the 
    :doi:`Ten Tusscher et al. 2004 model <10.1152/ajpheart.00794.2003>`.
  
    .. plot::
       :width: 300
       
       from ap_cvode import Tentusscher
       tt = Tentusscher()
       t, y, stats = tt.ap()
       fig = plt.figure()
       plt.plot(t, y.V, '.-')
       i = stats["i"]
       plt.plot(t[i], y.V[i], 'ro')
    
    This model's `main CellML page
    <http://models.cellml.org/exposure/c7f7ced1e002d9f0af1b56b15a873736>`_
    links to three versions of the model corresponding to different cell types:   
    :cellml:`a (midmyocardial)
    <c7f7ced1e002d9f0af1b56b15a873736/tentusscher_noble_noble_panfilov_2004_a>`,
    :cellml:`b (epicardial)
    <c7f7ced1e002d9f0af1b56b15a873736/tentusscher_noble_noble_panfilov_2004_b>`,
    :cellml:`c (endocardial)
    <c7f7ced1e002d9f0af1b56b15a873736/tentusscher_noble_noble_panfilov_2004_c>`.
    
    .. todo:: Could implement the three cell types as :meth:`~Bond.scenario`\ s.
    
    Other keyword arguments are passed through to 
    :class:`cellmlmodels.cellmlmodel.Cellmlmodel`.
    In particular, the "rename" argument changes some state and parameter 
    names to match those of the Bondarenko model, from which this class is 
    derived. Also, the constructor sets *stim_start* = 0.0, overriding the 
    default.
    
    >>> tentusscher = Tentusscher()
    >>> t, y, stats = tentusscher.ap()    
    >>> from pprint import pprint
    >>> pprint(stats)
    {'amp': array([ 121.108...]),
     'base': array([-86.2]),
     'caistats': {'amp': 0.0005032...,
                  'base': 0.0002000...,
                  'decayrate': array([ 0.0173...]),
                  'i': array([...]),
                  'p_repol': array([ 0.25,  0.5 ,  0.75,  0.9 ]),
                  'peak': 0.0007032...,
                  't_repol': array([  40.42...,   74.47...,  122.7...,  167.3...]),
                  'ttp': 10.1...},
     'decayrate': array([ 0.05060...]),
     'i': array([...]),
     'p_repol': array([ 0.25,  0.5 ,  0.75,  0.9 ]),
     'peak': array([ 34.908...]),
     't_repol': array([ 220.03...,  298.334...,  321.90...,  330.140...]),
     'ttp': 1.3481...}
    
    Doctest to alert if numerical results change.
    
    >>> [float(np.trapz(y[k], t, axis=0)) for k in "V", "Cai"]
    [-56243.7..., 0.1418...]
    """
    def __init__(self,
        exposure_workspace="c7f7ced1e002d9f0af1b56b15a873736/tentusscher_noble_noble_panfilov_2004_a",
        rename={"y": {"Na_i": "Nai", "Ca_i": "Cai", "K_i": "Ki"}, "p": {
            "IstimStart": "stim_start", 
            "IstimEnd": "stim_end", 
            "IstimAmplitude": "stim_amplitude", 
            "IstimPeriod": "stim_period", 
            "IstimPulseDuration": "stim_duration"
        }}, **kwargs):
        kwargs["rename"] = rename
        super(Tentusscher, self).__init__(exposure_workspace, **kwargs)
        self.pr.stim_start = 0

class Fitz(Bond):
    r"""
    CellML implementation of the FitzHugh-Nagumo nerve axon model.
    
    References:
        
    * Nagumo, J., Animoto, S., Yoshizawa, S. (1962)
      :doi:`An active pulse transmission line simulating nerve axon 
      <10.1109/JRPROC.1962.288235>`.
      Proc. Inst. Radio Engineers, 50, 2061-2070.
    * FitzHugh R (1961) 
      :doi:`Impulses and physiological states in theoretical models of nerve 
      membrane <10.1016/S0006-3495(61)86902-6>`. 
      Biophysical J. 1:445-466
    
    In Fitzhugh (1961), the definition of the transmembrane potential is 
    such that it decreases during depolarization, so that the action potential 
    starts with a downstroke, contrary to the convention used in FitzHugh 1969 
    and in most other work. The equations are also somewhat rearranged. 
    However, figure 1 of FitzHugh 1961 gives a very good overview of the phase 
    plane of the model.
    
    The nullclines of the model are:
    
    .. math::
    
        \dot{v} = 0 &\Leftrightarrow& w = v (v-\alpha) (1-v) + I \\
        \dot{w} = 0 &\Leftrightarrow& w = (1/\gamma) v
    
    A high gamma makes w change slowly relative to v, making the system more 
    stiff and the action potentials more "square".
    In the absence of a stimulus current, the model has a limit cycle if 
    :math:`\alpha \gamma < -1`
    
    I have made some hacks to make this model more commensurable with the 
    Bondarenko (2004) model. The current 
    :cellml:`CellML version <cf32346a9e5c4b2cdb559b11da5f1ae1/fitzhugh_1961>` 
    has stimulus duration and amplitude hardcoded, and the stimulus is not 
    periodic. I have hacked this in the CellML source for now.
    
    Also, I rename the state variable *v* to *V* for compatibility with the 
    pacing and clamping protocols.
    
    The hardcoded stimulus protocol in the CellML version is strange in that 
    the stimulus *decreases* the transmembrane potential, and with a magnitude 
    far beyond that of the model's action potential. My guess is that 
    *stim_duration* and *stim_amplitude* were copied directly from the 
    Bondarenko model.
    
    .. plot::
       :include-source:
       :width: 300
       
       from ap_cvode import Fitz
       fitz = Fitz(reltol=1e-10)
       for t, y, stats in fitz.aps(n=3):
           plt.plot(t, y.view(float))
    
    >>> fitz = Fitz(reltol=1e-10)
    >>> with fitz.autorestore():
    ...     t, y, stats = fitz.ap()
    >>> [float(stats[k]) for k in "base peak ttp".split()]
    [0.0, 0.984..., 28.27...]
    
    In fact, this parameter scenario is self-exciting even without a stimulus 
    current. :math:`(V=0, w=0)` is an equilibrium (though unstable), so we 
    choose a different initial value.
    
    .. plot::
        :include-source:
        :width: 300
        
        >>> from ap_cvode import Fitz
        >>> fitz = Fitz()
        >>> with fitz.autorestore(stim_amplitude=0, V=0.01):
        ...     t, y, flag = fitz.integrate(t=[0, 700])
        >>> plt.plot(t, y.view(float))                              # doctest: +SKIP
        >>> plt.legend(fitz.dtype.y.names)                          # doctest: +SKIP
    
    Estimate period of oscillation and verify that the last two maxima are 
    approximately equal.
    
    >>> from utils.extrema import extrema
    >>> (t0, v0), (t1, v1) = [(t[index], value) for index, value, curv 
    ...                         in extrema(y.V, min=False, withend=False)[-2:]]
    >>> s = "Period: %5.1f, First peak: %4.2f, Ratio of peaks: %5.3f"
    >>> print s % (t1-t0, v1, v1/v0)
    Period: 208.1, First peak: 0.97, Ratio of peaks: 1.000
    
    The constructor defines a "paced" :meth:`~Bond.scenario` where small 
    periodic stimuli elicit action potentials. To hack this, we impose a 
    negative stimulus most of the time, removing it briefly to elicit the 
    action potential.
    
    >>> with fitz.scenario("paced"):
    ...     L = list(fitz.aps(n=5))
    >>> [stats["ttp"] for t, y, stats in L[-2:]] # last two action potentials
    [1.00037..., 1.00073...]
    """
        
    def __init__(self, exposure_workspace="/fitzhugh_1961", 
            rename={"y": {"v": "V"}}, **kwargs):
        """
        Return a Fitzhugh (1961) model object.
        
        Keyword arguments are passed through to 
        :class:`~cellmlmodels.cellmlmodel.Cellmlmodel`.
        
        In particular, the *rename* argument changes some state and parameter 
        names to match those of the Bondarenko model, from which this class is 
        derived.
        
        See the class docstring for examples.
        """
        kwargs["rename"] = rename
        super(Fitz, self).__init__(exposure_workspace, **kwargs)
        pr = self.pr.copy()
        pr.stim_period = 200
        pr.stim_duration = 190
        pr.stim_amplitude = -0.1
        self.scenarios["paced"] = dict(p=pr, y=(0.01, 0.01))

class Hodgkin(Bond):
    """
    Hodgkin-Huxley model of action potential.
    
    I have made some hacks to make this model more commensurable with the 
    Bondarenko (2004) model. The current 
    :cellml:`CellML version <5d116522c3b43ccaeb87a1ed10139016/hodgkin_huxley_1952>` 
    has stimulus duration and amplitude hardcoded, and the stimulus is not 
    periodic. I have hacked this in the CellML source for now.
    I've also fixed a 0/0 bug in alpha_m for V == -50.
    
    >>> hh = Hodgkin()
    >>> t, y, stats = hh.ap()
    >>> ap_stats_array(stats)
    rec.array([ (107.3..., -75.0, 32.3..., 
    2.207..., 1.281..., 3.241..., 
    4.013..., 4.843..., 5.269...)],
    dtype=[('apamp', '<f8'), ('apbase', '<f8'), ('appeak', '<f8'), 
    ('apttp', '<f8'), ('apdecayrate', '<f8'), ('apd25', '<f8'), 
    ('apd50', '<f8'), ('apd75', '<f8'), ('apd90', '<f8')])
    >>> [stats["peak"] for t, y, stats in hh.aps(n=2)]
    [32.5688..., 32.5687...]
    
    Verify fix for 0/0 bug.
    
    >>> with hh.autorestore(V=-50):
    ...     t, y, stats = hh.ap()
    
    Before the fix, this produced:
    Traceback (most recent call last):
    CvodeException: CVode returned CV_CONV_FAILURE
    """
    def __init__(self, exposure_workspace="/hodgkin_huxley_1952", **kwargs):
        super(Hodgkin, self).__init__(exposure_workspace, **kwargs)

# Convert between "local time" starting at 0 in each interval, and "global time".

def globaltime(T):
    """
    Return cumulative "global" time from list of time vectors starting at 0

    >>> T = [0, 1, 2], [0, 1, 2, 3], [0, 1, 2, 3, 4]
    >>> globaltime(T)
    [[0, 1, 2], [2, 3, 4, 5], [5, 6, 7, 8, 9]]

    If you prefer a single vector:
    
    >>> np.concatenate(globaltime(T))
    array([0, 1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 9])
    """
    offset = np.cumsum([i[-1] for i in T])
    offset = np.r_[0, offset[:-1]]
    return [[o + ti for ti in t] for o, t in zip(offset, T)]

def localtime(T):
    """
    Return "local" time from a list of consecutive time vectors

    >>> T = [1, 2], [3, 4, 5], [6, 7, 8, 9]
    >>> localtime(T)
    [array([0, 1]), array([0, 1, 2]), array([0, 1, 2, 3])]
    """
    return [np.asanyarray(t) - t[0] for t in T]

def ap_stats_array(stats):
    """
    Convert action potential statistics from dict to structured ndarray.
    
    >>> from numpy import array
    >>> stats = {'amp' : 0.5, 'base': array([1.0]), 
    ...     'caistats': {'amp': 1.5, 'base': 2.0,
    ...         'decayrate': array([2.5]), 'i': array([1, 2, 3, 4, 5]), 
    ...         'p_repol': array([0.25, 0.5, 0.75, 0.9 ]),
    ...         'peak': 3.0, 't_repol': array([4.0, 5.0, 6.0, 7.0]), 'ttp': 8.0},
    ...     'decayrate': array([9.0]), 'i': array([6, 7, 8, 9, 10]),
    ...     'p_repol': array([0.25, 0.5, 0.75, 0.9]), 'peak': array([10.0]),
    ...     't_repol': array([11.0, 12.0, 13.0, 14.0]), 'ttp': 15.0}
    >>> ap_stats_array(stats)
    rec.array([ (0.5, 1.0, 10.0, 15.0, 9.0, 11.0, 12.0, 13.0, 14.0, 1.5, 
    2.0, 3.0, 8.0, 2.5, 4.0, 5.0, 6.0, 7.0)], 
    dtype=[('apamp', '<f8'), ('apbase', '<f8'), ('appeak', '<f8'), 
    ('apttp', '<f8'), ('apdecayrate', '<f8'), ('apd25', '<f8'), 
    ('apd50', '<f8'), ('apd75', '<f8'), ('apd90', '<f8'), ('ctamp', '<f8'), 
    ('ctbase', '<f8'), ('ctpeak', '<f8'), ('ctttp', '<f8'), 
    ('ctdecayrate', '<f8'), ('ctd25', '<f8'), ('ctd50', '<f8'), 
    ('ctd75', '<f8'), ('ctd90', '<f8')])
    
    >>> from ap_cvode import Li
    >>> li = Li()
    >>> t, y, stats = li.ap()
    >>> ap_stats_array(stats)
    rec.array([ (115.42..., -78.94..., 36.48..., 3.14..., 0.138..., 4.28..., 
    5.69..., 10.21..., 17.28..., 0.306..., 0.0949..., 0.401..., 28..., 
    0.0107..., 61.1..., 94.95..., 158..., 244.3...)], 
    dtype=[('apamp', '<f8'), ('apbase', '<f8'), ('appeak', '<f8'), 
    ('apttp', '<f8'), ('apdecayrate', '<f8'), ('apd25', '<f8'), 
    ('apd50', '<f8'), ('apd75', '<f8'), ('apd90', '<f8'), ('ctamp', '<f8'), 
    ('ctbase', '<f8'), ('ctpeak', '<f8'), ('ctttp', '<f8'), 
    ('ctdecayrate', '<f8'), ('ctd25', '<f8'), ('ctd50', '<f8'), 
    ('ctd75', '<f8'), ('ctd90', '<f8')])
    """
    names = "amp base peak ttp decayrate".split()
    n = len(names)
    names += ["d%d" % (100 * i) for i in stats["p_repol"]]
    if "caistats" in stats:
        dtype = [(var + name, float) for var in "ap", "ct" for name in names]
        data = np.r_[[float(stats[k]) for k in names[:n]],
                     stats["t_repol"],
                     [float(stats["caistats"][k]) for k in names[:n]],
                     stats["caistats"]["t_repol"]]
    else:
        dtype = [("ap" + name, float) for name in names]
        data = np.r_[[float(stats[k]) for k in names[:n]], stats["t_repol"]]
    return np.rec.array(data, dtype=dtype)

class Bond_uhc(Bond):
    """
    Bondarenko model with most constants unhardcoded.
    
    Comparing the details of the original and unhardcoded Bond models.
    
    >>> b = Bond()
    >>> bu = Bond_uhc()
    
    Increased number of parameters.
    
    >>> len(b.dtype.p), len(bu.dtype.p)
    (73, 204)
    
    Verify that the original parameters still have the same value.
    
    >>> for k in np.intersect1d(b.dtype.p.names, bu.dtype.p.names):
    ...     if b.pr[k] != bu.pr[k]:
    ...         print k, b.pr[k], bu.pr[k]
    
    The variable iKss was dropped because it was really a constant.
    
    >>> list(np.setdiff1d(b.dtype.y.names, bu.dtype.y.names))
    ['iKss']
    
    The sodium-calcium exchanger current was renamed.
    
    >>> list(np.setxor1d(b.dtype.a.names, bu.dtype.a.names))
    ['i_NCX', 'i_NaCa']
    
    Verify that action potential and calcium transient statistics are equal 
    for the original and unhardcoded model, to within roundoff error.
    
    >>> t, y, stats = b.ap()
    >>> tu, yu, statsu = bu.ap()
    >>> a, au = [ap_stats_array(i) for i in stats, statsu]
    
    >>> for k in a.dtype.names:
    ...     try:
    ...         np.testing.assert_almost_equal(a[k], au[k], decimal=5)
    ...     except AssertionError:
    ...         print k, a[k], au[k]
    ctttp [ 15.65...] [ 15.70...]
    """
    def __init__(self, exposure_workspace="/bond_uhc", *args, **kwargs):
        super(Bond_uhc, self).__init__(exposure_workspace, *args, **kwargs)

class Li_uhc(Li):
    """
    LNCS model with most constants unhardcoded.
    
    >>> li = Li()
    >>> liu = Li_uhc()
    >>> len(li.dtype.p), len(liu.dtype.p)
    (86, 188)
    >>> for k in np.intersect1d(li.dtype.p.names, liu.dtype.p.names):
    ...     if li.pr[k] != liu.pr[k]:
    ...         print k, li.pr[k], liu.pr[k]
    >>> list(np.setdiff1d(li.dtype.y.names, liu.dtype.y.names)) # dropped variable
    ['iKss']
    >>> li.dtype.a == liu.dtype.a
    True
    >>> t, y, stats = li.ap()
    >>> tu, yu, statsu = liu.ap()
    >>> a, au = [ap_stats_array(i) for i in stats, statsu]
    >>> for k in a.dtype.names:
    ...     if abs(1 - a[k] / au[k]) > 1e-3:
    ...         print k, a[k], au[k]
    """
    def __init__(self, exposure_workspace="/li_uhc", *args, **kwargs):
        super(Li_uhc, self).__init__(exposure_workspace, *args, **kwargs)

class Serca(Li):
    """
    Revised SERCA knockout with scenarios for FF (control), 4wk, 7wk.
    
    FF no longer includes a prepulses_number parameter, which is just as well.
    For consistency, prepulses_number is omitted in creating the 4wk and 7wk 
    scenarios.
    
    Verify fix for 0/0 error in 
    FF_210311_caffeine_NaKsubspace_SS_b_for_thesis.cellml.
    
    >>> m = Serca()
    >>> with m.clamp(V=0) as clamp:
    ...     dy, a = m.rates_and_algebraic(0, m.y)
    >>> a.i_anion
    array([ -7.14610...e-37])
    """
    def __init__(self, 
        exposure_workspace="/FF_210311_jov", 
        *args, **kwargs):
        super(Serca, self).__init__(exposure_workspace, *args, **kwargs)
        # Augment the Bond scenarios dict with 
        # initial state and parameters for three model scenarios.
        # nw means (name, workspace)
        modelnw = [("FF", "/FF_210311_caffeine_NaKsubspace_SS_b_for_thesis"), 
                   ("KO4wk", "/KO4wk_210311KO4wk_caffeine_NaKsubspace_SS_b_for_thesis"), 
                   ("KO7wk", "/KO7wk_170311KO_caffeine_NaKsubspace_SS_b_for_thesis")]
        for n, w in modelnw:
            self.scenarios[n] = dict(workspace=w, 
                                     y=self.y0r.copy(), p=self.pr.copy())
            m = Cellmlmodel(w)
            m.pr.stim_start = 0.0
            for k in set(m.dtype.p.names) & set(self.dtype.p.names):
                self.scenarios[n]["p"][k] = m.pr[k]
            for k in set(m.dtype.y.names) & set(self.dtype.y.names):
                self.scenarios[n]["y"][k] = m.y0r[k]

if __name__ == "__main__":
    import doctest
    doctest.testmod(optionflags=doctest.ELLIPSIS | doctest.NORMALIZE_WHITESPACE)
